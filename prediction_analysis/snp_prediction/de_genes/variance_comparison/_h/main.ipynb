{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine extreme partials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, errno\n",
    "import functools\n",
    "import pandas as pd\n",
    "import collections as cx\n",
    "from pybiomart import Dataset\n",
    "# GO analysis\n",
    "from goatools.base import download_go_basic_obo\n",
    "from goatools.base import download_ncbi_associations\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.anno.genetogo_reader import Gene2GoReader\n",
    "from goatools.goea.go_enrichment_ns import GOEnrichmentStudyNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cached functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache()\n",
    "def get_database():\n",
    "    dataset = Dataset(name=\"hsapiens_gene_ensembl\", \n",
    "                      host=\"http://www.ensembl.org\",\n",
    "                      use_cache=True)\n",
    "    db = dataset.query(attributes=[\"ensembl_gene_id\", \n",
    "                                   \"external_gene_name\", \n",
    "                                   \"entrezgene_id\"], \n",
    "                       use_attr_names=True).dropna(subset=['entrezgene_id'])\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_p(directory):\n",
    "    \"\"\"\n",
    "    Make a directory if it does not already exist.\n",
    "\n",
    "    Input: Directory name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "            \n",
    "def extract_top_bottom(tissue, ml_df, percent=0.05):\n",
    "    df = ml_df[(ml_df[\"Tissue\"] == tissue)].sort_values(\"Partial_R2\", ascending=False)\n",
    "    df[\"ensemblID\"] = df.Geneid.str.replace(\"\\\\..*\", \"\", regex=True)\n",
    "    n = round(df.shape[0] * percent)\n",
    "    top = df.head(n)\n",
    "    bottom = df.tail(n)\n",
    "    return top, bottom\n",
    "\n",
    "\n",
    "def extract_extremes(tissue, ml_df, val1, val2):\n",
    "    df = ml_df[(ml_df[\"Tissue\"] == tissue)].sort_values(\"Partial_R2\", ascending=False)\n",
    "    df[\"ensemblID\"] = df.Geneid.str.replace(\"\\\\..*\", \"\", regex=True)\n",
    "    return df[(df[\"Partial_R2\"] > val1)], df[(df[\"Partial_R2\"] < val2)]\n",
    "\n",
    "\n",
    "def old_convert2entrez(tissue, ml_df, percent):\n",
    "    top, bottom = extract_top_bottom(tissue, ml_df, percent)\n",
    "    df1 = top.merge(get_database(), left_on='ensemblID', \n",
    "                    right_on='ensembl_gene_id')\n",
    "    df2 = bottom.merge(get_database(), left_on=\"ensemblID\", \n",
    "                       right_on=\"ensembl_gene_id\")\n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "def convert2entrez(top, bottom):\n",
    "    df1 = top.merge(get_database(), left_on='ensemblID', \n",
    "                    right_on='ensembl_gene_id')\n",
    "    df2 = bottom.merge(get_database(), left_on=\"ensemblID\", \n",
    "                       right_on=\"ensembl_gene_id\")\n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "def obo_annotation(alpha=0.05):\n",
    "    # database annotation\n",
    "    fn_obo = download_go_basic_obo()\n",
    "    fn_gene2go = download_ncbi_associations() # must be gunzip to work\n",
    "    obodag = GODag(fn_obo) # downloads most up-to-date\n",
    "    anno_hs = Gene2GoReader(fn_gene2go, taxids=[9606])\n",
    "    # get associations\n",
    "    ns2assoc = anno_hs.get_ns2assc()\n",
    "    for nspc, id2gos in ns2assoc.items():\n",
    "        print(\"{NS} {N:,} annotated human genes\".format(NS=nspc, N=len(id2gos)))\n",
    "    goeaobj = GOEnrichmentStudyNS(\n",
    "        get_database()['entrezgene_id'], # List of human genes with entrez IDs\n",
    "        ns2assoc, # geneid/GO associations\n",
    "        obodag, # Ontologies\n",
    "        propagate_counts = False,\n",
    "        alpha = alpha, # default significance cut-off\n",
    "        methods = ['fdr_bh'])\n",
    "    return goeaobj\n",
    "\n",
    "\n",
    "def run_goea(tissue, top, bottom, dname, label=''):\n",
    "    df1, df2 = convert2entrez(top, bottom)\n",
    "    t_name = tissue.lower().replace(\" \", \"_\")\n",
    "    d = {\"Top\": df1, \"Bottom\": df2}\n",
    "    for study in [\"Top\", \"Bottom\"]:\n",
    "        print(study)\n",
    "        df = d[study]\n",
    "        geneids_study = {z[0]:z[1] for z in zip(df['entrezgene_id'], df['external_gene_name'])}\n",
    "        goeaobj = obo_annotation()\n",
    "        goea_results_all = goeaobj.run_study(geneids_study)\n",
    "        goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.05]\n",
    "        ctr = cx.Counter([r.NS for r in goea_results_sig])\n",
    "        print('Significant results[{TOTAL}] = {BP} BP + {MF} MF + {CC} CC'.format(\n",
    "            TOTAL=len(goea_results_sig),\n",
    "            BP=ctr['BP'], MF=ctr['MF'], CC=ctr['CC']))\n",
    "        if label == '':\n",
    "            goeaobj.wr_xlsx(\"%s/%s_GO_analysis_%s.xlsx\" % (dname, t_name, study), \n",
    "                            goea_results_sig)\n",
    "            goeaobj.wr_txt(\"%s/%s_GO_analysis_%s.txt\" % (dname, t_name, study), \n",
    "                           goea_results_sig)\n",
    "        else:\n",
    "            goeaobj.wr_xlsx(\"%s/%s_GO_analysis_%s_%s.xlsx\" % (dname, t_name, study, label), \n",
    "                            goea_results_sig)\n",
    "            goeaobj.wr_txt(\"%s/%s_GO_analysis_%s_%s.txt\" % (dname, t_name, study, label), \n",
    "                           goea_results_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract by tissue by Pst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net estimated Pst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"enet\"\n",
    "mkdir_p(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = pd.read_csv(\"../../partial_r2/enet_partial_r2_metrics.tsv\", sep='\\t')\n",
    "print(enet.shape)\n",
    "enet.groupby(\"Tissue\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet[(enet[\"Partial_R2\"] > 0.25)].groupby(\"Tissue\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet[(enet[\"Partial_R2\"] < 0.025)].groupby(\"Tissue\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enrichment and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 0.05; val1 = 0.25; val2 = 0.025\n",
    "top_df = pd.DataFrame()\n",
    "bottom_df = pd.DataFrame()\n",
    "for tissue in [\"Caudate\", \"DLPFC\", \"Dentate Gyrus\", \"Hippocampus\"]:\n",
    "    top, bottom = extract_extremes(tissue, enet, val1, val2)\n",
    "    run_goea(tissue, top, bottom, model)\n",
    "    top_df = pd.concat([top_df, top], axis=0)\n",
    "    bottom_df = pd.concat([bottom_df, bottom], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df[\"Variation_Explained\"] = \"High\"\n",
    "bottom_df[\"Variation_Explained\"] = \"Low\"\n",
    "dt = pd.concat([top_df, bottom_df], axis=0)\n",
    "dt.to_csv(\"%s/extremes_partial_r2_enet.tsv\" % model, sep='\\t', index=False)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest estimated Pst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"rf\"\n",
    "mkdir_p(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.read_csv(\"../../partial_r2/rf_partial_r2_metrics.tsv\", sep='\\t')\n",
    "print(rf.shape)\n",
    "rf.groupby(\"Tissue\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf[(rf[\"Partial_R2\"] > 0.25)].groupby(\"Tissue\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf[(rf[\"Partial_R2\"] < 0.01)].groupby(\"Tissue\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enrichment and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 0.05; val1 = 0.25; val2 = 0.01\n",
    "top_df = pd.DataFrame()\n",
    "bottom_df = pd.DataFrame()\n",
    "for tissue in [\"Caudate\", \"DLPFC\", \"Dentate Gyrus\", \"Hippocampus\"]:\n",
    "    top, bottom = extract_extremes(tissue, rf, val1, val2)\n",
    "    run_goea(tissue, top, bottom, model)\n",
    "    top_df = pd.concat([top_df, top], axis=0)\n",
    "    bottom_df = pd.concat([bottom_df, bottom], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df[\"Variation_Explained\"] = \"High\"\n",
    "bottom_df[\"Variation_Explained\"] = \"Low\"\n",
    "dt = pd.concat([top_df, bottom_df], axis=0)\n",
    "dt.to_csv(\"%s/extremes_partial_r2_rf.tsv\" % model, sep='\\t', index=False)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment of top and bottom 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"enet\"\n",
    "for tissue in [\"Caudate\", \"DLPFC\", \"Dentate Gyrus\", \"Hippocampus\"]:\n",
    "    df = enet[(enet[\"Tissue\"] == tissue)].sort_values(\"Partial_R2\", ascending=False)\n",
    "    df[\"ensemblID\"] = df.Geneid.str.replace(\"\\\\..*\", \"\", regex=True)\n",
    "    top = df.head(100)\n",
    "    bottom = df.tail(100)\n",
    "    run_goea(tissue, top, bottom, model, 'n100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"rf\"\n",
    "for tissue in [\"Caudate\", \"DLPFC\", \"Dentate Gyrus\", \"Hippocampus\"]:\n",
    "    df = rf[(rf[\"Tissue\"] == tissue)].sort_values(\"Partial_R2\", ascending=False)\n",
    "    df[\"ensemblID\"] = df.Geneid.str.replace(\"\\\\..*\", \"\", regex=True)\n",
    "    top = df.head(100)\n",
    "    bottom = df.tail(100)\n",
    "    run_goea(tissue, top, bottom, model, 'n100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
